# Gym-MuJoco

## 参考

### 文档

- [MuJoco](https://mujoco.readthedocs.io/en/latest/programming/simulation.html)

- [Gymnasium](https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/#sphx-glr-tutorials-gymnasium-basics-environment-creation-py)

- [Gymnasium-mujoco-robotics](https://robotics.farama.org/envs/MaMuJoCo/ma_ant/)

- 环境自定义
  - https://blog.csdn.net/qq_33446100/article/details/118249795

  - 强化学习的算法库
    - https://blog.csdn.net/qq_33446100/article/details/119089724?spm=1001.2014.3001.5502

  - 源码地址 https://github.com/openai/gym/blob/master/gym/core.py



### 教程

- 极简环境及注册

https://www.youtube.com/watch?v=ZxXKISVkH6Y&t=3s

- gym下-官方参考

![corepy的位置](../../assets/107_core.py-位置.png)



- Docs

![Gym教程文档](../../assets/108_Gym教程文档.webp)

- Agent

  - random_agent.py运行一个随机的智能体对象；

  - cem.py 使用交叉熵方法运行一个确定的智能体对象；

  - keyboard_agent.py 将自己作为智能体进行测试，将环境名称作为命令行参数传递。

    （scripts暂时没看明白用来做什么的。）

- 保存视频

  ```python
  from gym import wrappers
  from time import time # just to have timestamps in the files
  env = gym.make(ENV_NAME)
  env = wrappers.Monitor(env, './videos/' + str(time()) + '/')
  ```


# Gym-ENV-MuJoCo-Stable baselines 3

## 步骤

### 环境准备

- 安装

```shell
pip install stable-baselines3
```

- 阅读软件包

路径：`/home/ypq3/anaconda3/envs/Stone/lib/python3.10/site-packages/stable_baselines3`

### 封装程序包：

- 生成:`requirement.txt`


- Conda-环境包装

```sh
conda activate myenv
   conda env export > environment.yml
   conda list --export > requirements.txt
   conda env create -f environment.yml
   conda create --name myenv --file requirements.txt
```

- Pycharm：Tools ->Sync Python Requirements（同步python要求）
- pipreqs


```shell
# 安装
pip install pipreqs
# 在项目根目录下运行:
pipreqs ./ --encoding=utf8
```



- MuJoCo-src-read

  - 环境观察：
    - 可视化：坐标系、接触力、相机切换镜头、截屏、透视、隐藏菜单
    - 位于body下：
    - ``       <camera name="track" mode="trackcom" pos="0 -3 0.3" xyaxes="1 0 0 0 0 1"/>``
  - 类的继承架构
    - Ant-V4 -> MujocoEnv ->GymEnv

- SB-3

  - Demo-cart pole -gym
  - SB-3 src reading
    - Common
    - single algorithm
    - DDPG
      - 中级错题家
      - CSDN
  - Office Docs

- Mujoco-env

  - MyEnvStone
  - RL-Knowledge-
  - Gym-customer-env
  - DDPG-sb3

  - CUDA-PyTorch-issac
    - [PyTorch documentation — PyTorch 2.2 documentation](https://pytorch.org/docs/stable/index.html)
    - [主页 - PyTorch中文文档 (pytorch-cn.readthedocs.io)](https://pytorch-cn.readthedocs.io/zh/latest/)
  - 并行CPU
  - MuJoCo-JAX
  - TensorBoard

## TensorBoard

- Official

[Tensorboard Integration — Stable Baselines3 2.3.2 documentation (stable-baselines3.readthedocs.io)](https://stable-baselines3.readthedocs.io/en/master/guide/tensorboard.html)

- Install
- Usage

```python
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter(log_dir="your_log_dir")

from stable_baselines3 import PPO

model = PPO("MlpPolicy", "CartPole-v1", tensorboard_log=writer)
model.learn(total_timesteps=10000)
```

- Launch

```shell
tensorboard --logdir your_log_dir
```

- 浏览器地址：`localhost:6006`
