# 源码库





## 1. move_group_interface.py

```python
#!/usr/bin/env python
# use moveit_commander (the Python MoveIt user interfaces )
import sys
import copy
import rospy
import moveit_commander
import moveit_msgs.msg
import geometry_msgs.msg
from math import pi

class MoveGroupInteface(object):
	def __init__(self):
		super(MoveGroupInteface, self).__init__()
		######################### setup ############################
		moveit_commander.roscpp_initialize(sys.argv)
		rospy.init_node('ur_move_test_node', anonymous=True)
		self.robot = moveit_commander.RobotCommander()
		self.scene = moveit_commander.PlanningSceneInterface() 
		group_name = "manipulator"  
		self.move_group_commander = moveit_commander.MoveGroupCommander(group_name)
		self.display_trajectory_publisher = rospy.Publisher('/move_group/display_planned_path',moveit_msgs.msg.DisplayTrajectory,queue_size=20)
		
		################ Getting Basic Information ######################
		self.planning_frame = self.move_group_commander.get_planning_frame()
		print "============ Planning frame: %s" % self.planning_frame
		self.eef_link = self.move_group_commander.get_end_effector_link()
		print "============ End effector link: %s" % self.eef_link
		self.group_names = self.robot.get_group_names()
		print "============ Available Planning Groups:", self.robot.get_group_names()
		print "============ Printing robot state:"
		print self.robot.get_current_state()  
		print ""

	def plan_cartesian_path(self, scale=1):
		waypoints = []
		wpose = self.move_group_commander.get_current_pose().pose
		wpose.position.z -= scale * 0.1  # First move up (z)
		waypoints.append(copy.deepcopy(wpose))
		wpose.position.x += scale * 0.1  # Second move forward/backwards in (x)
		waypoints.append(copy.deepcopy(wpose))
		wpose.position.y += scale * 0.1  # Third move sideways (y)
		waypoints.append(copy.deepcopy(wpose))    

		# We want the Cartesian path to be interpolated at a resolution of 1 cm
		# which is why we will specify 0.01 as the eef_step in Cartesian
		# translation.  We will disable the jump threshold by setting it to 0.0,
		# ignoring the check for infeasible jumps in joint space, which is sufficient
		# for this tutorial.
		(plan, fraction) = self.move_group_commander.compute_cartesian_path(
										waypoints,   # waypoints to follow
										0.01,      # eef_step  
										0.0)         # jump_threshold  

		# Note: We are just planning, not asking move_group to actually move the robot yet:
		pring "=========== Planning completed, Cartesian path is saved============="
		return plan, fraction

	def execute_plan(self, plan):
		## Use execute if you would like the robot to follow
		## the plan that has already been computed:
		self.move_group_commander.execute(plan, wait=True)

print "----------------------------------------------------------"
print "Welcome to the MoveIt MoveGroup Python Interface Tutorial"
print "----------------------------------------------------------"
print "Press Ctrl-D to exit at any time"
print ""
print "============ Press `Enter` to begin the tutorial by setting up the moveit_commander ..."
raw_input()
tutorial = MoveGroupInteface()
print "============ Press `Enter` to plan and display a Cartesian path ..."
raw_input()
cartesian_plan, fraction = tutorial.plan_cartesian_path()
print "============ Press `Enter` to execute a saved path  ..."
raw_input()
tutorial.execute_plan(cartesian_plan)
print "============ Press `Enter` to go back ..."
raw_input()
cartesian_plan, fraction = tutorial.plan_cartesian_path(scale=-1)
tutorial.execute_plan(cartesian_plan)
```

## 2. 笛卡尔路径规划.py

```python
import rospy, sys
import moveit_commander
from moveit_commander import MoveGroupCommander
from geometry_msgs.msg import Pose
from copy import deepcopy

class MoveItCartesianDemo:
    def __init__(self):
        # 初始化move_group的API
        moveit_commander.roscpp_initialize(sys.argv)

        # 初始化ROS节点
        rospy.init_node('moveit_cartesian_demo', anonymous=True)
        
        # 是否需要使用笛卡尔空间的运动规划
        cartesian = rospy.get_param('~cartesian', True)
                        
        # 初始化需要使用move group控制的机械臂中的arm group
        arm = MoveGroupCommander('arm')
        
        # 当运动规划失败后，允许重新规划
        arm.allow_replanning(True)
        
        # 设置目标位置所使用的参考坐标系
        arm.set_pose_reference_frame('base_link')
                
        # 设置位置(单位：米)和姿态（单位：弧度）的允许误差
        arm.set_goal_position_tolerance(0.01)
        arm.set_goal_orientation_tolerance(0.1)
        
        # 获取终端link的名称
        end_effector_link = arm.get_end_effector_link()
                                        
        # 控制机械臂运动到之前设置的“forward”姿态
        arm.set_named_target('forward')
        arm.go()
        
        # 获取当前位姿数据最为机械臂运动的起始位姿
        start_pose = arm.get_current_pose(end_effector_link).pose
                
        # 初始化路点列表
        waypoints = []
                
        # 将初始位姿加入路点列表
        if cartesian:
            waypoints.append(start_pose)
            
        # 设置第二个路点数据，并加入路点列表
        # 第二个路点需要向后运动0.2米，向右运动0.2米
        wpose = deepcopy(start_pose)
        wpose.position.x -= 0.2
        wpose.position.y -= 0.2

        if cartesian:
            waypoints.append(deepcopy(wpose))
        else:
            arm.set_pose_target(wpose)
            arm.go()
            rospy.sleep(1)
         
        # 设置第三个路点数据，并加入路点列表
        wpose.position.x += 0.05
        wpose.position.y += 0.15
        wpose.position.z -= 0.15
          
        if cartesian:
            waypoints.append(deepcopy(wpose))
        else:
            arm.set_pose_target(wpose)
            arm.go()
            rospy.sleep(1)
        
        # 设置第四个路点数据，回到初始位置，并加入路点列表
        if cartesian:
            waypoints.append(deepcopy(start_pose))
        else:
            arm.set_pose_target(start_pose)
            arm.go()
            rospy.sleep(1)
            
        if cartesian:
            fraction = 0.0   #路径规划覆盖率
            maxtries = 100   #最大尝试规划次数
            attempts = 0     #已经尝试规划次数
            
            # 设置机器臂当前的状态作为运动初始状态
            arm.set_start_state_to_current_state()
     
            # 尝试规划一条笛卡尔空间下的路径，依次通过所有路点
            while fraction < 1.0 and attempts < maxtries:
                (plan, fraction) = arm.compute_cartesian_path (
                                        waypoints,   # waypoint poses，路点列表
                                        0.01,        # eef_step，终端步进值
                                        0.0,         # jump_threshold，跳跃阈值
                                        True)        # avoid_collisions，避障规划
                
                # 尝试次数累加
                attempts += 1
                
                # 打印运动规划进程
                if attempts % 10 == 0:
                    rospy.loginfo("Still trying after " + str(attempts) + " attempts...")
                         
            # 如果路径规划成功（覆盖率100%）,则开始控制机械臂运动
            if fraction == 1.0:
                rospy.loginfo("Path computed successfully. Moving the arm.")
                arm.execute(plan)
                rospy.loginfo("Path execution complete.")
            # 如果路径规划失败，则打印失败信息
            else:
                rospy.loginfo("Path planning failed with only " + str(fraction) + " success after " + str(maxtries) + " attempts.")  

        # 控制机械臂回到初始化位置
        arm.set_named_target('home')
        arm.go()
        rospy.sleep(1)
        
        # 关闭并退出moveit
        moveit_commander.roscpp_shutdown()
        moveit_commander.os._exit(0)

if __name__ == "__main__":
    try:
        MoveItCartesianDemo()
    except rospy.ROSInterruptException:
        pass
```

- 报错

  - 注释：

  - ```shell
    ABORTED: Solution found but controller failed during execution
    # 将初始位姿加入列表
    waypoints.append(start_pose)
    ```



## 3. Add_collision.cpp

```cpp
// ROS
#include <ros/ros.h>
// MoveIt
#include <moveit/planning_scene_interface/planning_scene_interface.h>
#include <moveit/move_group_interface/move_group_interface.h>
// TF2
#include <tf2_geometry_msgs/tf2_geometry_msgs.h>

void addCollisionObjects(moveit::planning_interface::PlanningSceneInterface& planning_scene_interface)
{
 // Create vector to hold 3 collision objects.
  std::vector<moveit_msgs::CollisionObject> collision_objects;
  collision_objects.resize(3);

  // Add the first table where the cube will originally be kept.
  collision_objects[0].id = "grasp_table";
  collision_objects[0].header.frame_id = "world";

  /* Define the primitive and its dimensions. */
  collision_objects[0].primitives.resize(1);
  collision_objects[0].primitives[0].type = collision_objects[0].primitives[0].BOX;
  collision_objects[0].primitives[0].dimensions.resize(3);
  collision_objects[0].primitives[0].dimensions[0] = 0.6;
  collision_objects[0].primitives[0].dimensions[1] = 0.9;
  collision_objects[0].primitives[0].dimensions[2] = 0.608;

  /* Define the pose of the table. */
  collision_objects[0].primitive_poses.resize(1);
  collision_objects[0].primitive_poses[0].position.x = 0.6;
  collision_objects[0].primitive_poses[0].position.y = 0;
  collision_objects[0].primitive_poses[0].position.z = 0;
  // END_SUB_TUTORIAL

  collision_objects[0].operation = collision_objects[0].ADD;

  // BEGIN_SUB_TUTORIAL table2
  // Add the second table where we will be placing the cube.
  collision_objects[1].id = "left_table";
  collision_objects[1].header.frame_id = "world";

  /* Define the primitive and its dimensions. */
  collision_objects[1].primitives.resize(1);
  collision_objects[1].primitives[0].type = collision_objects[1].primitives[0].BOX;
  collision_objects[1].primitives[0].dimensions.resize(3);
  collision_objects[1].primitives[0].dimensions[0] = 0.6;
  collision_objects[1].primitives[0].dimensions[1] = 0.9;
  collision_objects[1].primitives[0].dimensions[2] = 0.608;

  /* Define the pose of the table. */
  collision_objects[1].primitive_poses.resize(1);
  collision_objects[1].primitive_poses[0].position.x = 0;
  collision_objects[1].primitive_poses[0].position.y = -0.7;
  collision_objects[1].primitive_poses[0].position.z = 0;
  collision_objects[1].primitive_poses[0].orientation.x = 0;
  collision_objects[1].primitive_poses[0].orientation.y = 0;
  collision_objects[1].primitive_poses[0].orientation.z = 0.707;
  collision_objects[1].primitive_poses[0].orientation.w = 0.707;
  // END_SUB_TUTORIAL

  collision_objects[1].operation = collision_objects[1].ADD;

  // BEGIN_SUB_TUTORIAL object
  // Define the object that we will be manipulating
  collision_objects[2].header.frame_id = "world";
  collision_objects[2].id = "right_table";

  /* Define the primitive and its dimensions. */
  collision_objects[2].primitives.resize(1);
  collision_objects[2].primitives[0].type = collision_objects[1].primitives[0].BOX;
  collision_objects[2].primitives[0].dimensions.resize(3);
  collision_objects[2].primitives[0].dimensions[0] = 0.6;
  collision_objects[2].primitives[0].dimensions[1] = 0.9;
  collision_objects[2].primitives[0].dimensions[2] = 0.608;

  /* Define the pose of the object. */
  collision_objects[2].primitive_poses.resize(1);
  collision_objects[2].primitive_poses[0].position.x = 0;
  collision_objects[2].primitive_poses[0].position.y = 0.7;
  collision_objects[2].primitive_poses[0].position.z = 0;
  collision_objects[1].primitive_poses[0].orientation.x = 0;
  collision_objects[1].primitive_poses[0].orientation.y = 0;
  collision_objects[1].primitive_poses[0].orientation.z = 0.707;
  collision_objects[1].primitive_poses[0].orientation.w = 0.707;
  // END_SUB_TUTORIAL

  collision_objects[2].operation = collision_objects[2].ADD;

  planning_scene_interface.applyCollisionObjects(collision_objects);
}
int main(int argc, char** argv)
{
  ros::init(argc, argv, "add_tablex3");
  ros::NodeHandle nh;
  ros::AsyncSpinner spinner(1);
  spinner.start();

  ros::WallDuration(1.0).sleep();
  moveit::planning_interface::PlanningSceneInterface planning_scene_interface;
  addCollisionObjects(planning_scene_interface);

  ros::WallDuration(1.0).sleep();
  return 0;
}
```

## 4. pick-moveit.cpp

```cpp
#include <string>
#include <ros/ros.h>
#include <moveit/move_group_interface/move_group_interface.h>
 
int main(int argc, char **argv)
{
    //初始化节点
    ros::init(argc, argv, "moveit_demo");
    //多线程
    ros::AsyncSpinner spinner(1);
    //开启线程
    spinner.start();
 
    //初始化需要使用move group控制的机械臂中的arm group
    moveit::planning_interface::MoveGroupInterface arm("manipulator");
 
    //获取终端link的名称
    std::string end_effector_link = arm.getEndEffectorLink();
 
    //设置目标位置所使用的参考坐标系
    std::string reference_frame = "base_link";
    arm.setPoseReferenceFrame(reference_frame);
 
    //当运动规划失败后，允许重新规划
    arm.allowReplanning(true);
 
    //设置位置(单位：米)和姿态（单位：弧度）的允许误差
    arm.setGoalPositionTolerance(0.001);
    arm.setGoalOrientationTolerance(0.01);
 
    //设置允许的最大速度和加速度
    arm.setMaxAccelerationScalingFactor(0.2);
    arm.setMaxVelocityScalingFactor(0.2);
 
    // 控制机械臂先回到初始化位置
    arm.setNamedTarget("base");
    arm.move(); //规划+运动
    sleep(1); //停1s钟
 
    // 设置机器人终端的目标位置
    geometry_msgs::Pose target_pose;
    //四元数，设置末端姿态
    target_pose.orientation.x = 0.70692;
    target_pose.orientation.y = 0.0;
    target_pose.orientation.z = 0.0;
    target_pose.orientation.w = 0.70729;
    //设置末端位置
    target_pose.position.x = 0.2593;
    target_pose.position.y = 0.0636;
    target_pose.position.z = 0.1787;
 
    // 设置机器臂当前的状态作为运动初始状态
    arm.setStartStateToCurrentState();
    // 将目标位姿写入
    arm.setPoseTarget(target_pose);
 
    // 进行运动规划，计算机器人移动到目标的运动轨迹，此时只是计算出轨迹，并不会控制机械臂运动
    moveit::planning_interface::MoveGroupInterface::Plan plan;
    moveit::planning_interface::MoveItErrorCode success = arm.plan(plan);
 
    //输出成功与否的信息
    ROS_INFO("Plan (pose goal) %s",success?"":"FAILED");   
 
    //让机械臂按照规划的轨迹开始运动
    if(success)
      arm.execute(plan);
    sleep(1);
 
    // 控制机械臂先回到初始化位置
    arm.setNamedTarget("base");
    arm.move();
    sleep(1);
 
    ros::shutdown(); 
 
    return 0;
}
```

## 5. pick.py

```python
import rospy, sys
import moveit_commander
from geometry_msgs.msg import PoseStamped, Pose


class MoveItIkDemo:
    def __init__(self):
     # 初始化move_group的API
    moveit_commander.roscpp_initialize(sys.argv)
    
    # 初始化ROS节点
    rospy.init_node('moveit_ik_demo')
            
    # 初始化需要使用move group控制的机械臂中的arm group
    arm = moveit_commander.MoveGroupCommander('manipulator')
            
    # 获取终端link的名称，这个在setup assistant中设置过了
    end_effector_link = arm.get_end_effector_link()
                    
    # 设置目标位置所使用的参考坐标系
    reference_frame = 'base_link'
    arm.set_pose_reference_frame(reference_frame)
            
    # 当运动规划失败后，允许重新规划
    arm.allow_replanning(True)
    
    # 设置位置(单位：米)和姿态（单位：弧度）的允许误差
    arm.set_goal_position_tolerance(0.001)
    arm.set_goal_orientation_tolerance(0.01)
   
    # 设置允许的最大速度和加速度
    arm.set_max_acceleration_scaling_factor(0.5)
    arm.set_max_velocity_scaling_factor(0.5)
 
    # 控制机械臂先回到初始化位置
    arm.set_named_target('home')
    arm.go()
    rospy.sleep(1)
           
    # 设置机械臂工作空间中的目标位姿，位置使用x、y、z坐标描述，
    # 姿态使用四元数描述，基于base_link坐标系
    target_pose = PoseStamped()
    #参考坐标系，前面设置了
    target_pose.header.frame_id = reference_frame
    target_pose.header.stamp = rospy.Time.now() #时间戳？
    #末端位置   
    target_pose.pose.position.x = 0.2593
    target_pose.pose.position.y = 0.0636
    target_pose.pose.position.z = 0.1787
    #末端姿态，四元数
    target_pose.pose.orientation.x = 0.70692
    target_pose.pose.orientation.y = 0.0
    target_pose.pose.orientation.z = 0.0
    target_pose.pose.orientation.w = 0.70729
    
    # 设置机器臂当前的状态作为运动初始状态
    arm.set_start_state_to_current_state()
    
    # 设置机械臂终端运动的目标位姿
    arm.set_pose_target(target_pose, end_effector_link)
    
    # 规划运动路径，返回虚影的效果
    traj = arm.plan()
    
    # 按照规划的运动路径控制机械臂运动
    arm.execute(traj)
    rospy.sleep(1)  #执行完成后休息1s
 
    # 控制机械臂回到初始化位置
    arm.set_named_target('home')
    arm.go()
 
    # 关闭并退出moveit
    moveit_commander.roscpp_shutdown()
    moveit_commander.os._exit(0)
if __name__ == "__main__":
    MoveItIkDemo()
```

```python
#! /usr/bin/env python
import sys
import rospy
import moveit_commander
import geometry_msgs
import tf
 
 
moveit_commander.roscpp_initializer.roscpp_initialize(sys.argv)
rospy.init_node('move_group_grasp', anonymous=True)
robot = moveit_commander.robot.RobotCommander()
 
arm_group = moveit_commander.move_group.MoveGroupCommander("manipulator")
hand_group = moveit_commander.move_group.MoveGroupCommander("gripper")
 
#hand_group.set_named_target("close")
#plan = hand_group.go()
 
 
 
arm_group.set_named_target("base")
plan = arm_group.go()
 
print("Point 1")
 
# Open
#hand_group.set_joint_value_target([9.800441184282249e-05, -9.800441184282249e-05, 9.800441184282249e-05, 9.800441184282249e-05, -9.800441184282249e-05, 9.800441184282249e-05])
#hand_group.go(wait=True)
#print("Point 2")
hand_group.set_named_target("open")
plan = hand_group.go()
print("Point 2")
 
 
pose_target = arm_group.get_current_pose().pose
 
# Block point
pose_target.position.x = 0.69
pose_target.position.y = 0.0
pose_target.position.z = pose_target.position.z
 
 
 
arm_group.set_pose_target(pose_target)
arm_group.go(wait=True)
print("Point 3")
 
# Block point
pose_target.position.x = 0.69
pose_target.position.y = 0.0
pose_target.position.z = pose_target.position.z-0.23
 
 
 
arm_group.set_pose_target(pose_target)
arm_group.go(wait=True)
print("Point 4")
 
 
hand_group.set_named_target("close")
plan = hand_group.go()
print("Point 5")
 
pose_target.position.z = pose_target.position.z+0.1
arm_group.set_pose_target(pose_target)
plan = arm_group.go()
print("Point 6")
 
 
pose_target.position.z = pose_target.position.z
pose_target.position.x = 1.0
arm_group.set_pose_target(pose_target)
plan = arm_group.go()
print("Point 7")
 
 
 
hand_group.set_named_target("open")
plan = hand_group.go()
print("Point 8")
 
rospy.sleep(5)
moveit_commander.roscpp_initializer.roscpp_shutdown()
```

## 6. GPD-订阅处理编写.cpp

> 参考：https://blog.csdn.net/flyfish1986/article/details/85266537?ops_request_misc=%7B%22request_id%22%3A%22168317010616800197096407%22%2C%22scm%22%3A%2220140713.130102334..%22%7D

```cpp
//std
#include <tuple>
#include <map>
#include <vector>
#include <queue>
#include <mutex>
#include <string>

// PCL
#include <pcl/io/pcd_io.h>
#include <pcl/filters/random_sample.h>
#include <pcl/point_types.h>
#include <pcl_conversions/pcl_conversions.h>
// ROS

#include <ros/ros.h>
#include <ros/callback_queue.h>
#include <sensor_msgs/PointCloud2.h>
#include <visualization_msgs/MarkerArray.h>

#include <sensor_msgs/JointState.h>
#include <std_msgs/Float64MultiArray.h>
#include <std_msgs/Empty.h>
#include <std_srvs/SetBool.h>
#include <std_msgs/Int64.h>
#include <std_msgs/Empty.h>
// this project (services)

// GPG
#include <gpg/cloud_camera.h>

// this project (messages)
#include <gpd/CloudIndexed.h>
#include <gpd/CloudSamples.h>
#include <gpd/CloudSources.h>
#include <gpd/GraspConfig.h>
#include <gpd/GraspConfigList.h>
#include <gpd/SamplesMsg.h>
#include <gpd/detect_grasps.h>

//tf
#include <tf/transform_listener.h>
#include <tf_conversions/tf_eigen.h>
//moveit  

#include <geometry_msgs/PoseStamped.h>
#include <geometry_msgs/PoseArray.h>
#include <moveit/move_group_interface/move_group_interface.h>
#include <moveit/planning_scene_interface/planning_scene_interface.h>
#include <moveit/planning_scene_monitor/planning_scene_monitor.h>
#include <moveit/robot_state/conversions.h>
#include <moveit/ompl_interface/ompl_interface.h>
#include <moveit/dynamics_solver/dynamics_solver.h>




//action
#include <actionlib/client/simple_action_client.h>
#include <control_msgs/FollowJointTrajectoryAction.h>
#include <trajectory_msgs/JointTrajectoryPoint.h>


#include <dynamic_reconfigure/server.h>


//GraspConfigList的解释
// # This message stores a list of grasp configurations.

// # The time of acquisition, and the coordinate frame ID.
// Header header

// # The list of grasp configurations.
// gpd/GraspConfig[] grasps


// # Position
// geometry_msgs/Point bottom # centered bottom/base of the robot hand)
// geometry_msgs/Point top # centered top/fingertip of the robot hand)
// geometry_msgs/Point surface # centered position on object surface

// # Orientation represented as three axis (R = [approach binormal axis])
// geometry_msgs/Vector3 approach # The grasp approach direction
// geometry_msgs/Vector3 binormal # The binormal
// geometry_msgs/Vector3 axis # The hand axis

// geometry_msgs/Point sample # Point at which the grasp was found

// std_msgs/Float32 width # Required aperture (opening width) of the robot hand

// std_msgs/Float32 score # Score assigned to the grasp by the classifier
void detect_grasps_callback(const gpd::GraspConfigList& l)
{
  // 将此消息转换成moveit能够识别的消息
  gpd::GraspConfig g = l.grasps[0];

  //将自定义形式转换成标准的多种形式输出

  double coefficient = M_PI / 180;
  double roll, pitch, yaw;

// File: geometry_msgs/Vector3.msg
// Raw Message Definition
// # This represents a vector in free space. 
// # It is only meant to represent a direction. Therefore, it does not
// # make sense to apply a translation to it (e.g., when applying a 
// # generic rigid transformation to a Vector3, tf2 will only apply the
// # rotation). If you want your data to be translatable too, use the
// # geometry_msgs/Point message instead.

// float64 x
// float64 y
// float64 z


tf::Matrix3x3 m(
g.approach.x, g.binormal.x, g.axis.x, 
g.approach.y, g.binormal.y, g.axis.y, 
g.approach.z, g.binormal.z, g.axis.z); 


            m.getEulerYPR(yaw, pitch, roll); //RPY提供给人肉眼看


            std::cout << m.getRow(0).getX() << m.getRow(0).getY() << m.getRow(0).getZ() << std::endl;
            std::cout << m.getRow(1).getX() << m.getRow(1).getY() << m.getRow(1).getZ() << std::endl;
            std::cout << m.getRow(2).getX() << m.getRow(2).getY() << m.getRow(2).getZ() << std::endl;


            geometry_msgs::Point point;
            point.x = g.sample.x;
            point.y = g.sample.y;
            point.z = g.sample.z;
            //输出x,y,z，r,p,y
             ROS_INFO("output xyzrpy: %f  %f  %f  %f  %f  %f", point.x ,point.y ,point.z, roll, pitch, yaw);

            geometry_msgs::PoseStamped target_pose_stamped; //四元数提供给计算机使用
            target_pose_stamped.pose.position.x = point.x;
            target_pose_stamped.pose.position.y = point.y;
            target_pose_stamped.pose.position.z = point.z;
            target_pose_stamped.pose.orientation = tf::createQuaternionMsgFromRollPitchYaw(roll, pitch, yaw);
}

int main(int argc, char *argv[])
{
  const std::string FRAME = "world";

  ros::init(argc, argv, "get_grasps"); //初始化ROS节点
  ros::NodeHandle n; //创建节点句柄

  ros::Subscriber sub = n.subscribe("/detect_grasps/clustered_grasps", 1000 , detect_grasps_callback);

  ros::Rate rate(1);
  while (ros::ok())
  {
    ros::spinOnce();
    rate.sleep();
  }
  

  return 0;
}

```

- Grasp转化为pose的编写

> https://blog.csdn.net/flyfish1986/article/details/86245823?ops_request_misc=

```c++
# This message describes a 2-finger grasp configuration by its 6-DOF pose, 
# consisting of a 3-DOF position and 3-DOF orientation, and the opening 
# width of the robot hand.

# Position
geometry_msgs/Point bottom # centered bottom/base of the robot hand)
geometry_msgs/Point top # centered top/fingertip of the robot hand)
geometry_msgs/Point surface # centered position on object surface

# Orientation represented as three axis (R = [approach binormal axis])
geometry_msgs/Vector3 approach # The grasp approach direction
geometry_msgs/Vector3 binormal # The binormal
geometry_msgs/Vector3 axis # The hand axis

geometry_msgs/Point sample # Point at which the grasp was found

std_msgs/Float32 width # Required aperture (opening width) of the robot hand 

std_msgs/Float32 score # Score assigned to the grasp by the classifier
# standard pose 
geometry_msgs/Point position
geometry_msgs/Quaternion orientation
  
  
```

- 转化代码

```c++
geometry_msgs::msg::Pose  grasp_to_pose (gpd::GraspConfig & grasp)
{

  geometry_msgs::msg::Pose pose;
  tf2::Matrix3x3 orientation(
    grasp.approach.x, grasp.binormal.x, grasp.axis.x,
    grasp.approach.y, grasp.binormal.y, grasp.axis.y,
    grasp.approach.z, grasp.binormal.z, grasp.axis.z);

  tf2::Quaternion orientation_quat;
  orientation.getRotation(orientation_quat);
  orientation_quat.normalize();
  pose.orientation.x = orientation_quat.x();
  pose.orientation.y = orientation_quat.y();
  pose.orientation.z = orientation_quat.z();
  pose.orientation.w = orientation_quat.w();

  pose.position = grasp.top;

  return pose;
}
```

- 最终代码

```c++
#include <ros/ros.h>
#include <gpd/GraspConfig.h>
#include <gpd/GraspConfigList.h>
#include <tf/transform_listener.h>
#include <tf_conversions/tf_eigen.h>
#include <geometry_msgs/PoseStamped.h>
#include <geometry_msgs/PoseArray.h>
ros::Publisher pub;
geometry_msgs::Pose pose;
//callback function: grasp2pose transform
void grasp_to_pose(const gpd::GraspConfigList& l)
{
  gpd::GraspConfig g = l.grasps[0];

//get grasp matrix
  tf::Matrix3x3 orientation(
    g.approach.x, g.binormal.x, g.axis.x,
    g.approach.y, g.binormal.y, g.axis.y,
    g.approach.z, g.binormal.z, g.axis.z);
//transform to quaterniion
  tf::Quaternion orientation_quat;
  orientation.getRotation(orientation_quat);
  orientation_quat.normalize();
//put in pose
  pose.orientation.x = orientation_quat.x();
  pose.orientation.y = orientation_quat.y();
  pose.orientation.z = orientation_quat.z();
  pose.orientation.w = orientation_quat.w();
  pose.position = g.top;
//print the inform
  std::cout << "PQ： completed the grasp2pose" << std::endl;
  std::cout << "Position: (" << pose.position.x << ", " << pose.position.y << ", " << pose.position.z << ")" << std::endl;
std::cout << "Orientation: (" << pose.orientation.x << ", " << pose.orientation.y << ", " 
          << pose.orientation.z << ", " << pose.orientation.w << ")" << std::endl;
  pub.publish(pose);
}

int main(int argc, char *argv[])
{
  const std::string FRAME = "base_link";

  ros::init(argc, argv, "get_grasps2pose"); 
  ros::NodeHandle n; 
  
//receive the grasp
  ros::Subscriber sub = n.subscribe("/detect_grasps/clustered_grasps", 1000 , grasp_to_pose);
//publish the pose 

  pub = n.advertise<geometry_msgs::Pose>("/objection_position_pose",1000);  

  
    ros::Rate rate(1);
  while (ros::ok())
  {
    ros::spinOnce();
    rate.sleep();
  }
  

  return 0;
}
```

- `CMakelists.txt`

```cmake
add_executable(${PROJECT_NAME}_grasp2pose src/ypq/grasp2pose.cpp)

target_link_libraries(${PROJECT_NAME}_grasp2pose
                      ${GENERATOR_LIB}
                      ${catkin_LIBRARIES})
set_target_properties(${PROJECT_NAME}_grasp2pose
                      PROPERTIES OUTPUT_NAME grasp2pose
                      PREFIX "")
```

##  7. 坐标变换.cpp

- 发布者

```cpp
#include "ros/ros.h"
#include "tf2_ros/static_transform_broadcaster.h"
#include "geometry_msgs/TransformStamped.h"
#include "tf2/LinearMath/Quaternion.h"

int main(int argc, char *argv[])
{
    setlocale(LC_ALL,"");
    // 2.初始化 ROS 节点
    ros::init(argc,argv,"static_brocast");
    // 3.创建静态坐标转换广播器
    tf2_ros::StaticTransformBroadcaster broadcaster;
    // 4.创建坐标系信息
    geometry_msgs::TransformStamped ts;
    //----设置头信息
    ts.header.seq = 100;
    ts.header.stamp = ros::Time::now();
    ts.header.frame_id = "base_link";
    //----设置子级坐标系
    ts.child_frame_id = "laser";
    //----设置子级相对于父级的偏移量
    ts.transform.translation.x = 0.2;
    ts.transform.translation.y = 0.0;
    ts.transform.translation.z = 0.5;
    //----设置四元数:将 欧拉角数据转换成四元数
    tf2::Quaternion qtn;
    qtn.setRPY(0,0,0);
    ts.transform.rotation.x = qtn.getX();
    ts.transform.rotation.y = qtn.getY();
    ts.transform.rotation.z = qtn.getZ();
    ts.transform.rotation.w = qtn.getW();
    // 5.广播器发布坐标系信息
    broadcaster.sendTransform(ts);
    ros::spin();
    return 0;
}

```

 - 接受者：进行转换过程

```cpp
#include "ros/ros.h"
#include "tf2_ros/transform_listener.h"
#include "tf2_ros/buffer.h"
#include "geometry_msgs/PointStamped.h"
#include "tf2_geometry_msgs/tf2_geometry_msgs.h" //注意: 调用 transform 必须包含该头文件

int main(int argc, char *argv[])
{
    setlocale(LC_ALL,"");
    // 2.初始化 ROS 节点
    ros::init(argc,argv,"tf_sub");
    ros::NodeHandle nh;
    // 3.创建 TF 订阅节点
    tf2_ros::Buffer buffer;
    tf2_ros::TransformListener listener(buffer);

    ros::Rate r(1);
    while (ros::ok())
    {
    // 4.生成一个坐标点(相对于子级坐标系)
        geometry_msgs::PointStamped point_laser;
        point_laser.header.frame_id = "laser";
        point_laser.header.stamp = ros::Time::now();
        point_laser.point.x = 1;
        point_laser.point.y = 2;
        point_laser.point.z = 7.3;
        // 5.转换坐标点(相对于父级坐标系)
        // 新建一个坐标点，用于接收转换结果  
        //--------------使用 try 语句或休眠，否则可能由于缓存接收延迟而导致坐标转换失败------------------------
        try
        {
            geometry_msgs::PointStamped point_base;
            point_base = buffer.transform(point_laser,"base_link");
            ROS_INFO("转换后的数据:(%.2f,%.2f,%.2f),参考的坐标系是:%s",point_base.point.x,point_base.point.y,point_base.point.z,point_base.header.frame_id.c_str());

        }
        catch(const std::exception& e)
        {
            // std::cerr << e.what() << '\n';
            ROS_INFO("程序异常.....");
        }

        r.sleep();  
        ros::spinOnce();
    }
    return 0;
}

```

https://blog.csdn.net/weixin_40799950/article/details/83620820?spm=1001.2014.3001.5502

grasp2pose.cpp

```cpp
# Robot Hand Geometry Parameters:
#   finger_width: the width of the finger
#   outer_diameter: the diameter of the robot hand (= maximum aperture plus 2 * finger width)
#   hand_depth: the finger length (measured from hand base to finger tip)
#   hand_height: the height of the hand
#   init_bite: the minimum distance between the fingertip and the side of the object that is oriented toward the hand
finger_width = 0.01
hand_outer_diameter = 0.12
hand_depth = 0.06
hand_height = 0.02
init_bite = 0.01

# Preprocessing of Point Cloud
#   voxelize: if the point cloud gets voxelixed
#   remove_outliers: if statistical outliers are removed from the point cloud (used to remove noise)
#   workspace: the workspace of the robot manipulator
#   camera_pose: the pose of the camera that took the point cloud
voxelize = 1
remove_outliers = 0
workspace = -1.0 1.0 -1.0 1.0 -1.0 1.0
camera_pose = 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1

# Grasp Candidate Generation
#   num_samples: the number of samples to be drawn from the point cloud
#   num_threads: the number of CPU threads to be used
#   nn_radius: the radius for the neighborhood search
#   num_orientations: the number of robot hand orientations to evaluate
#   rotation_axis: the axis about which the point neighborhood gets rotated
num_samples = 5
num_threads = 4
nn_radius = 0.01
num_orientations = 1
rotation_axis = 2

# Visualization
#   plot_grasps: if the grasp candidates found are plotted with PCL
#   plot_normals: if the calculated surface normals are plotted with PCL
plot_grasps = 1
plot_normals = 1
```

- 修改：`grasp_gpd.py`

```python
# 需要导入模块: import tf2_ros [as 别名]
# 或者: from tf2_ros import LookupException [as 别名]
def convert_pose(pose, from_frame, to_frame):
    """
    Convert a pose or transform between frames using tf.
        pose            -> A geometry_msgs.msg/Pose that defines the robots position and orientation in a reference_frame
        from_frame      -> A string that defines the original reference_frame of the robot
        to_frame        -> A string that defines the desired reference_frame of the robot to convert to
    """
    global tfBuffer, listener

    # Create Listener objet to recieve and buffer transformations
    trans = None

    try:
        trans = tfBuffer.lookup_transform(to_frame, from_frame, rospy.Time(0), rospy.Duration(1.0))
    except (tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException), e:
        print(e)
        rospy.logerr('FAILED TO GET TRANSFORM FROM %s to %s' % (to_frame, from_frame))
        return None 
```

- 编写tf发布方

```csharp
#include "ros/ros.h"
#include "tf2_ros/static_transform_broadcaster.h"
#include "geometry_msgs/TransformStamped.h"
#include "tf2/LinearMath/Quaternion.h"

int main(int argc, char *argv[])
{
    setlocale(LC_ALL,"");
    // 2.初始化 ROS 节点
    ros::init(argc,argv,"cam2world_brocast");
    // 3.创建静态坐标转换广播器
    tf2_ros::StaticTransformBroadcaster broadcaster;
    // 4.创建坐标系信息
    geometry_msgs::TransformStamped cam2world;
    //----设置
 cam2world.header.seq = 100;
 cam2world.header.stamp = ros::Time::now();
 cam2world.header.frame_id = "world";
 cam2world.child_frame_id = "kinect2_base_link";

 cam2world.transform.translation.x= 0.5 ;
 cam2world.transform.translation.y= 0.0 ;
 cam2world.transform.translation.z= 1.5 ;
 cam2world.transform.rotation.x= 0.0 ; 
 cam2world.transform.rotation.y= 0.707106781; 
 cam2world.transform.rotation.z= 0.0 ; 
 cam2world.transform.rotation.w= 0.707106781 ;
    // 5.广播器发布坐标系信息
    broadcaster.sendTransform(cam2world);
    ros::spin();
    return 0;
}



#include <ros/ros.h>

#include <gpd/GraspConfig.h>
#include <gpd/GraspConfigList.h>

#include <tf/transform_listener.h>
#include <tf/transform_broadcaster.h>


#include <geometry_msgs/PoseStamped.h>
#include <geometry_msgs/PoseArray.h>
#include <geometry_msgs/TransformStamped.h>

#include "tf2_ros/static_transform_broadcaster.h"
#include "tf2/LinearMath/Quaternion.h"
#include "tf2_geometry_msgs/tf2_geometry_msgs.h"

geometry_msgs::Pose obj_pose;
geometry_msgs::PoseStamped obj2world;
geometry_msgs::PoseStamped obj2cam;

//callback function: grasp2pose transform
void grasp_to_pose(const gpd::GraspConfigList& l)
{
  gpd::GraspConfig g = l.grasps[0];

//get grasp matrix
  tf::Matrix3x3 orientation(
    g.approach.x, g.binormal.x, g.axis.x,
    g.approach.y, g.binormal.y, g.axis.y,
    g.approach.z, g.binormal.z, g.axis.z);
//transform to quaterniion
  tf::Quaternion orientation_quat;
  orientation.getRotation(orientation_quat);
  orientation_quat.normalize();
// put in obj2cam
obj2cam.header.seq = 99;
obj2cam.header.stamp = ros::Time::now();
obj2cam.header.frame_id = "kinecet2_base_link";

obj2cam.pose.position = g.top;
obj2cam.pose.orientation.x = orientation_quat.getX();
obj2cam.pose.orientation.y = orientation_quat.getY();
obj2cam.pose.orientation.z = orientation_quat.getZ();
obj2cam.pose.orientation.w = orientation_quat.getW();

//print the inform
  std::cout << "PQ： completed the grasp2pose" << std::endl;
  std::cout << "position: (" << obj_pose.position.x << ", " << obj_pose.position.y << ", " << obj_pose.position.z << ")" << std::endl;
  std::cout << "orientation: (" << obj_pose.orientation.x << ", " << obj_pose.orientation.y << ", " << obj_pose.orientation.z << ", " << obj_pose.orientation.w << ")" << std::endl;

}

int main(int argc, char *argv[])
{
  const std::string FRAME = "kinect2_base_link";

  ros::init(argc, argv, "grasps2pose_1"); 
  ros::NodeHandle n; 
  tf2_ros::Buffer buffer;
  tf2_ros::TransformListener listener(buffer);
//receive the grasp
  ros::Subscriber sub = n.subscribe("/detect_grasps/clustered_grasps", 1000 , grasp_to_pose);
//listen to the TF2 
   try
        {
   listener.transformPose("world",obj2cam, obj2world);
//point_base = buffer.transform(point_laser,"base_link");
//ROS_INFO("转换后的数据:(%.2f,%.2f,%.2f),参考的坐标系是:",point_base.point.x,point_base.point.y,point_base.point.z,point_base.header.frame_id.c_str());

        }
        catch(const std::exception& e)
        {
            // std::cerr << e.what() << '\n';
            ROS_INFO("程序异常.....");
        }
   obj_pose.position=obj2world.pose.position;
   obj_pose.orientation=obj2world.pose.orientation;
  
  ros::Publisher pub;
  pub.publish(obj_pose);
  pub = n.advertise<geometry_msgs::Pose>("/objection_pose",1000);  
    ros::Rate rate(1);
  while (ros::ok())
  {
    ros::spinOnce();
    rate.sleep();
  }
    return 0;
}
```



```c
#include <ros/ros.h>
// #include <geometry_msgs/PointStamped.h>
#include "geometry_msgs/PoseStamped.h"
#include "geometry_msgs/Pose.h"
#include <tf/transform_listener.h>
#include <tf/transform_broadcaster.h>
#include <visualization_msgs/MarkerArray.h> 
 
geometry_msgs::PoseStamped real_pose;
geometry_msgs::PoseStamped transed_pose;
 
void transformPose(const tf::TransformListener& listener){
  //we'll create a point in the base_laser frame that we'd like to transform to the base_link frame
  // geometry_msgs::PointStamped laser_point;
  // geometry_msgs::PoseStamped msg;
  // laser_point.header.frame_id = "camera_link";
  // real_pose.header.frame_id = "camera_link";
  real_pose.header.frame_id = "camera_rgb_optical_frame";
  // real_pose.header.frame_id = "camera_rgb_frame";
  //we'll just use the most recent transform available for our simple example
  // laser_point.header.stamp = ros::Time();
  real_pose.header.stamp = ros::Time();
  real_pose.pose.position.x = -0.0521919690073; 
  real_pose.pose.position.y = 0.0947469994426; 
  real_pose.pose.position.z = 0.928996682167;   
  real_pose.pose.orientation.w = 0.487851679325; 
  real_pose.pose.orientation.x = 0.518789410591; 
  real_pose.pose.orientation.y = -0.516209602356; 
  real_pose.pose.orientation.z = 0.47580036521; 
  //just an arbitrary point in space
  try{
    listener.transformPose("base_link", real_pose, transed_pose);
  }
  catch(tf::TransformException& ex){
    ROS_ERROR("Received an exception trying to transform a point from \"camera_rgb_optical_frame\" to \"base_link\": %s", ex.what());
  }
}

int main(int argc, char** argv){
  ros::init(argc, argv, "tf_listener_Posetransform");
  ros::NodeHandle n;
  tf::TransformListener listener(ros::Duration(10));
  //we'll transform a point once every second
  ros::Timer timer = n.createTimer(ros::Duration(1.0), boost::bind(&transformPose, boost::ref(listener)));
  ros::Publisher my_publisher_realPose = n.advertise<geometry_msgs::PoseStamped>("real_pose", 1000);
  ros::Publisher my_publisher_transedPose = n.advertise<geometry_msgs::PoseStamped>("transed_pose", 1000);
  ros::Rate loop_rate(10);
  while (ros::ok())
      {
        my_publisher_transedPose.publish(transed_pose);
        my_publisher_realPose.publish(real_pose);
 
        ros::spinOnce();
        loop_rate.sleep();
      }
  ros::spin();
  return 0;
}
```

