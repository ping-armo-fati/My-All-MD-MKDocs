# gpd

## 参考
[GIT-hub官方](https://github.com/atenpas/gpd/tree/forward)
[还不错的CSND教程](https://blog.csdn.net/Eeko_x/article/details/104835154?ops_request_misc=)
[GPD-代码书写](https://blog.csdn.net/flyfish1986/article/details/85266537?ops_request_misc=%7B%22request%5Fid%22%3A%22168317010616800197096407%22%2C%22scm%22%3A%2220140713.130102334..%22%7D)
[安装-报错教程](https://blog.csdn.net/m0_53621852/article/details/121915687?ops_request_misc={request_id:168397346716800226512568,scm:20140713.130102334..})
[安装-报错教程1](https://blog.csdn.net/qq_34935373/article/details/105159680?ops_request_misc=%7B%22request%5Fid%22%3A%22168317032916800213066994%22%2C%22scm%22%3A%2220140713.130102334..%22%7D)
[GPD工作空间的设置](https://blog.csdn.net/flyfish1986/article/details/85791858?ops_request_misc=%7B%22request%5Fid%22%3A%22168317010616800197096407%22%2C%22scm%22%3A%2220140713.130102334..%22%7D)
[PCL-ROS Index](https://index.ros.org/p/pcl_ros/github-ros-perception-perception_pcl/#kinetic)
[PCL](https://blog.csdn.net/shine_cherise/article/details/79285162)
[PCL-ROS 使用](https://blog.csdn.net/qq_42367689/article/details/104358046?ops_request_misc=%7B%22request%5Fid%22%3A%22168317076016782427492152%22%2C%22scm%22%3A%2220140713.130102334..%22%7D)
[GPD-标准POSE](https://blog.csdn.net/flyfish1986/article/details/86245823?ops_request_misc=)

## 官方教程
### UR5 Video
<http://www.youtube.com/watch?feature=player_embedded&v=kfe5bNt35ZI>

### Requirements

1. [PCL 1.7 or later](http://pointclouds.org/)
2. [Eigen 3.0 or later](https://eigen.tuxfamily.org)
3. <a href="http://wiki.ros.org/indigo" style="color:blue">ROS Indigo</a> <span style="color:blue">and Ubuntu 
14.04</span> *or* <a href="http://wiki.ros.org/kinetic" style="color:orange">ROS Kinetic</a> 
<span style="color:orange">and Ubuntu 16.04</span>


### Prerequisites

The following instructions work for **Ubuntu 14.04** or **Ubuntu 16.04**. Similar instructions should work for other 
Linux distributions that support ROS.

1. Install ROS. 

2. Clone the [grasp_pose_generator](https://github.com/atenpas/gpg) repository into some folder:

   ```
   cd <location_of_your_workspace>
   git clone https://github.com/atenpas/gpg.git
   ```

3. Build and install the *grasp_pose_generator*: 

   ```
   cd gpg
   mkdir build && cd build
   cmake ..
   make
   sudo make install
   ```


### Compiling GPD

1. Clone this repository.
   
   ```
   cd <location_of_your_workspace/src>
   git clone https://github.com/atenpas/gpd.git
   ```

2. Build your catkin workspace.

   ```
   cd <location_of_your_workspace>
   catkin_make
   ```


### Generate Grasps for a Point Cloud File

Launch the grasp pose detection on an example point cloud:

   ```
   roslaunch gpd tutorial0.launch
   ```
Within the GUI that appears, press <kbd>r</kbd> to center the view, and <kbd>q</kbd> to quit the GUI and load the next visualization.
The output should look similar to the screenshot shown below.
### RS Camera
```
roslaunch realsense2_camera rs_camera.launch filters:=pointcloud
rosrun rviz rviz 
```
进入 rviz 界面后, 左下角点击 “Add”, 点击 By topic, 选中 /camera/depth/color/points/PointCloud2 后点击 “OK”

将 Global Options 下 Fixed Frame 栏，选定 camera_link，得到相机点云图
### 启动GPD
用文本编辑器打开gpd/launch/tutorial1.launch

找到下面的参数，将value后面的值改为你深度相机发布点云的topic，这里我修改为了: /camera/depth/color/points
```
<param name="cloud_topic" value="/camera/depth/color/points" />
```
- 启动GPD
```
roslaunch gpd tutorial1.launch
```
### 在Python中使用得到的Grasps，参考代码
```
import rospy
from gpd.msg import GraspConfigList

# global variable to store grasps
grasps = []


# Callback function to receive grasps.
def callback(msg):
    global grasps
    grasps = msg.grasps


# ==================== MAIN ====================
# Create a ROS node.
rospy.init_node('get_grasps')

# Subscribe to the ROS topic that contains the grasps.
sub = rospy.Subscriber('/detect_grasps/clustered_grasps', GraspConfigList, callback)

# Wait for grasps to arrive.
rate = rospy.Rate(1)

while not rospy.is_shutdown():
    print '.'
    if len(grasps) > 0:
        rospy.loginfo('Received %d grasps.', len(grasps))
        break
    rate.sleep()
```

## Tutorials

1. [Detect Grasps With an RGBD camera](tutorials/tutorial_1_grasps_camera.md)
2. [Detect Grasps on a Specific Object](tutorials/tutorial_2_grasp_select.md)


### Parameters

Brief explanations of parameters are given in *launch/classify_candidates_file_15_channels.launch* for using PCD files. 
For use on a robot, see *launch/ur5_15_channels.launch*. The two parameters that you typically want to play with to 
improve on then number of grasps found are *workspace* and *num_samples*. The first defines the volume of space in which 
to search for grasps as a cuboid of dimensions [minX, maxX, minY, maxY, minZ, maxZ], centered at the origin. The second 
is the number of samples that are drawn from the point cloud to detect grasps. You should set the workspace as small as 
possible and the number of samples as large as possible. 

## 具体操作
### 关于-GPD的git 参考较好的CSDN的教程

- 下载不要在`master`分支，而要选择`GPD-forward`，是一种预训练模型

### 具体操作

- <kbd>R</kbd>使得画面居中，<kbd>q</kbd>退出当前抓取，并发布后进行下一次检测
- Rviz中订阅，话题：`detect_grasps/marker topic`

### ImportError: No module named scipy
<https://blog.csdn.net/qq_41204464/article/details/103575669>
```
sudo apt-get install python-scipy
pip install scipy
pip install scipy  --user
pip3 install scipy  --user
```
### eigen3.3及以上安装
> https://blog.csdn.net/CC977/article/details/122972719
> https://eigen.tuxfamily.org/dox-3.3/GettingStarted.html
> https://blog.csdn.net/weixin_43399515/article/details/124049189?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124049189-blog-122972719.235%5Ev36%5Epc_relevant_default_base3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124049189-blog-122972719.235%5Ev36%5Epc_relevant_default_base3&utm_relevant_index=2
> https://blog.csdn.net/KNOW_MORE/article/details/86922474
> https://blog.csdn.net/weixin_38172545/article/details/106567522
> https://blog.csdn.net/weixin_43399515/article/details/124049189?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124049189-blog-122972719.235%5Ev36%5Epc_relevant_default_base3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124049189-blog-122972719.235%5Ev36%5Epc_relevant_default_base3&utm_relevant_index=2
> 执行：
>  sudo cp /usr/include/eigen339/share/eigen3/cmake/*.cmake  /usr/lib/cmake/eigen3/

